{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pandas as pd\n",
    "import json\n",
    "import seaborn as sns\n",
    "from random import randint, choice\n",
    "from os import path\n",
    "from main_data import (\n",
    "    key_to_camelot,\n",
    "    open_wheel,\n",
    "    add_features,\n",
    "    get_playlist,\n",
    "    get_friendly,\n",
    "    pickl,\n",
    "    unpickl,\n",
    "    sp,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %store -r streams_df streams_af_df no_skip_df playlist_af_df\n",
    "# streams_df, streams_af_df, no_skip_df, playlist_af_df = streams_df, streams_af_df, no_skip_df, playlist_af_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DataFrames generated by main_data.py\n",
    "def imp():\n",
    "    global all_streams_df, streams_df, streams_af_df, no_skip_df, playlist_af_df, pod_df, wheel_df\n",
    "    (\n",
    "        all_streams_df,\n",
    "        streams_df,\n",
    "        streams_af_df,\n",
    "        no_skip_df,\n",
    "        playlist_af_df,\n",
    "        pod_df,\n",
    "        wheel_df,\n",
    "    ) = unpickl(\n",
    "        \"all_streams_df.p\",\n",
    "        \"streams_df.p\",\n",
    "        \"streams_af_df.p\",\n",
    "        \"no_skip_df.p\",\n",
    "        \"playlist_af_df.p\",\n",
    "        \"podcasts_df.p\",\n",
    "        \"wheel_df.p\",\n",
    "    )\n",
    "    # return all_streams_df, streams_df, streams_af_df, no_skip_df, playlist_af_df, pod_df, wheel_df = import_all()\n",
    "\n",
    "# todo: move to main\n",
    "\n",
    "def hpm_rollback(pod):\n",
    "    # refactoring of hpm() that works with pandas 1.4.2\n",
    "    pod.loc[:, \"hours\"] = pod.loc[:, \"playtime\"].copy() / 3600\n",
    "    pod.index = pod.timestamp\n",
    "    podm = (\n",
    "        pod.copy()\n",
    "        .loc[:, \"hours\"]\n",
    "        .resample(\"M\")\n",
    "        .apply(lambda x: np.sum(x.values))\n",
    "        .round()\n",
    "    )\n",
    "    podm_gb = (\n",
    "        podm.groupby(podm.index.strftime(\"%b\"))\n",
    "        .resample(\"Y\")\n",
    "        .apply(lambda x: np.sum(x.values))\n",
    "        .round()\n",
    "        .droplevel(level=1)\n",
    "    )\n",
    "    podm_gb = podm_gb.groupby(podm_gb.index).mean()\n",
    "    return podm_gb\n",
    "\n",
    "\n",
    "def hpm(df):\n",
    "    df.loc[:, \"hours\"] = df.loc[:, \"playtime\"].copy() / 3600\n",
    "    df = df.groupby(['month', pd.Grouper(key='timestamp', freq='Y')])['playtime'].sum().groupby(\"month\").mean()\n",
    "    return df\n",
    "\n",
    "def plthpm(sgb):\n",
    "    return sns.barplot(data=sgb.iloc[0:0], x=sgb.values, y=sgb.index)\n",
    "\n",
    "# def plothpm(\n",
    "#     plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "# sns.barplot(data=podm_gb, x=podm_gb[\"hours\"], y=podm_gb.index)\n",
    "# )\n",
    "\n",
    "\n",
    "def top_songs(years=\"all\", skips=False, features=True):\n",
    "    if skips and features:\n",
    "        df = streams_af_df\n",
    "    elif not skips:\n",
    "        df = df.query(\"(playtime / duration) > 0.51\").reset_index()\n",
    "    # todo complete this\n",
    "\n",
    "def format_td(td):\n",
    "    \"\"\"Converts timedelta to hh:mm:ss strictly for presentation purposes\"\"\"\n",
    "    minutes, seconds = divmod(td.seconds + td.days * 86400, 60)\n",
    "    hours, minutes = divmod(minutes, 60)\n",
    "    return \"{:d}:{:02d}:{:02d}\".format(hours, minutes, seconds, td.microseconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imp()\n",
    "# streams_af_df.timestamp = streams_af_df.timestamp.dt.tz_convert(\"America/New_York\")\n",
    "#todo convert abq listening to mountain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playtime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>217.660833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>213.599722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200.713056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>195.744722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>177.740278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>176.846111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>174.491389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>172.493056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>161.819167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>158.727222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>151.931111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>151.456944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>149.001111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>144.687778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>142.730278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>127.047222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>125.061111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>109.176944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>88.719444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>81.838889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>72.057778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>68.047222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>67.970556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>60.024444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             playtime\n",
       "timestamp            \n",
       "0          217.660833\n",
       "1          213.599722\n",
       "2          200.713056\n",
       "23         195.744722\n",
       "4          177.740278\n",
       "22         176.846111\n",
       "21         174.491389\n",
       "3          172.493056\n",
       "5          161.819167\n",
       "20         158.727222\n",
       "17         151.931111\n",
       "18         151.456944\n",
       "19         149.001111\n",
       "16         144.687778\n",
       "15         142.730278\n",
       "6          127.047222\n",
       "14         125.061111\n",
       "13         109.176944\n",
       "7           88.719444\n",
       "12          81.838889\n",
       "8           72.057778\n",
       "9           68.047222\n",
       "10          67.970556\n",
       "11          60.024444"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "streams_af_df# I don't recall listening to this artist so much. Investigating if it was on repeat on accident or something.\n",
    "why_tala = tstreams_df#.query('\"Hope Tala\" in artist')\n",
    "why_why_tala = (\n",
    "    why_tala.loc[:, ['playtime', 'timestamp']].groupby(by=why_tala.timestamp.dt.hour)\n",
    "    .sum(numeric_only=True)\n",
    "    .sort_values(by=\"playtime\", ascending=False))\n",
    "why_why_tala[\"playtime\"] = why_why_tala[\"playtime\"].apply(lambda x: x / 3600)\n",
    "why_why_tala.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q# Looks like I just let her run on most popular song repeat for a few hours.\n",
    "streams_af_df.query('date == \"11/27/2019\"').sort_values(by=\"timestamp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_skip_df.query('artist.str.contains(\"(?i)miles davis\")', engine=\"python\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[streams_df.year.unique().values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randyear(df):\n",
    "    return choice(range(streams_df.timestamp.dt.year.min(), \n",
    "                        streams_df.timestamp.dt.year.max() +1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streams_af_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sp.search(\"Black Dove\")\n",
    "track = result['tracks']['items'][0]\n",
    "\n",
    "artist = sp.artist(track[\"artists\"][0][\"external_urls\"][\"spotify\"])\n",
    "print(\"artist genres:\", artist[\"genres\"])\n",
    "\"\"\"\n",
    "how to aggregate playtime when results are lisre\n",
    "of genres?\n",
    "\n",
    "query genres for all tracks\n",
    "\"\"\"\n",
    "\n",
    "imp()\n",
    "print(type([[artist[\"genres\"]]]))\n",
    "#genre = pd.DataFrame({\"artist\": \"Teebs\", \"genre\": artist[\"genres\"]})\n",
    "sorte = streams_af_df.sort_values(by=\"playtime\")\n",
    "genre = sorte.iloc[0:7, :]\n",
    "print(genre)\n",
    "genre[\"jenre\"] = [[artist[\"genres\"][0]]]\n",
    "#genre = genre.explode(\"genre\")\n",
    "genre\n",
    "\n",
    "#going to need to collapse into just artists and playtime before \n",
    "# exploding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streams_af_df.sort_values(by=\"playtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_skips(deef):\n",
    "    return deef.query(\"(playtime / duration) > 0.51\").reset_index()\n",
    "\n",
    "pod_df = pod_df.rename(columns={\"episode\": \"track\", \"show\": \"artist\"})\n",
    "\n",
    "def top_songs(df, years=False, skips=False, rand=False):\n",
    "    if not skips:\n",
    "        df = del_skips(df) \n",
    "    if rand:\n",
    "        years = randyear(df)\n",
    "    elif years:\n",
    "        cols = [\"artist\", \"track\", \"year\"]\n",
    "    elif not years:\n",
    "        years = df.timestamp.dt.year.unique()\n",
    "        cols = [\"artist\", \"track\"]\n",
    "    return pd.DataFrame(df.query(\"timestamp.dt.year in @years\").pivot_table(columns=cols, aggfunc=\"size\").sort_values(ascending=False))\n",
    "    \n",
    "    #todo works for artist if thats the omly col\n",
    "    # make cols=[] and append based on conditions\n",
    "\n",
    "top_songs(streams_df, skips=True).head(30)\n",
    "\n",
    "#todo: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_track = pd.DataFrame(\n",
    "    no_skip_df.query('year == \"2022\"')\n",
    "    .pivot_table(columns=[\"artist\", \"track\", \"year\"], aggfunc=\"size\")\n",
    "    .sort_values(ascending=False))\n",
    "\n",
    "pivot_track.head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_skip_df.query('year == \"2022\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check for tracks missing from new df\n",
    "# series1 = duration_prep['spotify_track_uri']\n",
    "# series2 = local_features['uri']\n",
    "# comparison = series1[~series1.isin(series2)]\n",
    "# comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show missing track URLs for further investigation; track is likely removed or yet to be analyzed for audio_features.\n",
    "# missing_tracks = []\n",
    "# for i in range(len(comparison)):\n",
    "#     missing_tracks.append(sp.track(comparison.iloc[i])['external_urls'])\n",
    "# missing_tracks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most played tracks\n",
    "pivot_track = pd.DataFrame(\n",
    "    no_skip_df.pivot_table(columns=[\"artist\", \"track\"], aggfunc=\"size\").sort_values(\n",
    "        ascending=False\n",
    "    )\n",
    ")\n",
    "pivot_track\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most listened to artists by number of songs played\n",
    "pivot_artist = pd.DataFrame(\n",
    "    no_skip_df.pivot_table(columns=[\"artist\"], aggfunc=\"size\").sort_values(\n",
    "        ascending=False\n",
    "    )\n",
    ")\n",
    "pivot_artist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_skip_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miles = no_skip_df.query('artist.str.contains(\"(?i)Miles Davis\")')\n",
    "pivot_miles = pd.pivot_table(miles, values=\"playtime\", index=[\"album\"], aggfunc=\"sum\")\n",
    "pivot_miles = pivot_miles.sort_values(by=\"playtime\", ascending=False)\n",
    "miles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_album_time = pd.pivot_table(\n",
    "    no_skip_df, values=\"playtime\", index=[\"album\"], aggfunc=\"sum\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_album_time = pivot_album_time.sort_values(by=\"playtime\", ascending=False)\n",
    "pivot_album_time.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_artist_time = pd.pivot_table(\n",
    "    no_skip_df, values=\"playtime\", index=[\"artist\"], aggfunc=\"sum\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pivot_artist_time.sort_values().to_string())\n",
    "artist_time = pivot_artist_time.sort_values(\n",
    "    by=\"playtime\", ascending=False\n",
    ").reset_index()\n",
    "print(artist_time.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artists played more than 10 mins\n",
    "repeated_artists = artist_time[:1750]\n",
    "# Number of unique tracks played from those artists\n",
    "\n",
    "len(streams_af_df[\"track\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "still_repeated = repeated_artists[\"artist\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of unique tracks per artist and create ascending list\n",
    "still_still_repeated = no_skip_df.query(\"artist in @still_repeated\")\n",
    "# still_still_repeated.loc[:, 'artist'] = still_still_repeated.copy().loc[:, 'artist'].astype(str)\n",
    "group = still_still_repeated.groupby(\"artist\")\n",
    "songs_per_artist = group.apply(lambda x: x[\"track\"].unique())\n",
    "unique_songs = songs_per_artist.reset_index(name=\"unique_titles\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_songs[\"unique_count\"] = unique_songs.iloc[:, 1].str.len()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_songs = unique_songs.sort_values(by=\"unique_count\").reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_export = unique_songs.query(\"unique_count <= 8\")[\"artist\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_artist_time.playtime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artists with 10 or less songs played that I've heard more than an hour of. Indicative of artists I should explore more of.\n",
    "pivot_artist_time.query(\"playtime > 3600000\").query(\"artist in @unique_export\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo: Next step after the above is to plot least uniques with most ms played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert\n",
    "pivot_artist_time[\"playtime\"] = pd.to_timedelta(pivot_artist_time.playtime, unit=\"ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_td(td):\n",
    "    \"\"\"Converts timedelta to hh:mm:ss strictly for presentation purposes\"\"\"\n",
    "    minutes, seconds = divmod(td.seconds + td.days * 86400, 60)\n",
    "    hours, minutes = divmod(minutes, 60)\n",
    "    return \"{:d}:{:02d}:{:02d}\".format(hours, minutes, seconds, td.microseconds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_artist_time[\"playtime\"] = pivot_artist_time[\"playtime\"].apply(format_td)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show longest songs\n",
    "no_skip_df.sort_values(by=\"playtime\", axis=0, ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to control this for missing months? do october 25 2019 thru 2022\n",
    "sns_prep = streams_af_df.query('year == \"2019\"| year == \"2020\" | year == \"2021\"')\n",
    "sns_prep = pd.pivot_table(\n",
    "    sns_prep,\n",
    "    values=\"playtime\",\n",
    "    index=[\"month\"],\n",
    "    aggfunc=\"sum\",\n",
    ").reset_index()\n",
    "sns_prep[\"hours played\"] = sns_prep[\"playtime\"].apply(lambda x: x / 3600000)\n",
    "sns.barplot(data=sns_prep, x=\"month\", y=\"hours played\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of unique uris closely maps to total skips per month\n",
    "sns_prep = streams_af_df.copy().drop_duplicates(subset=\"id\")\n",
    "sns_prep[\"count\"] = 1\n",
    "sns_prep = (\n",
    "    sns_prep.loc[:, [\"month\", \"duration\", \"playtime\", \"shuffle\", \"count\"]]\n",
    "    .groupby(by=\"month\")\n",
    "    .sum(numeric_only=True)\n",
    ")\n",
    "sns.barplot(data=sns_prep, x=sns_prep.index, y=\"count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good way to find months with most music discovery along with unique URIs\n",
    "sns_prep = streams_af_df.copy().query(\"(playtime / duration) < 0.25\")\n",
    "sns_prep.at[:, \"count\"] = 1\n",
    "sns_prep = (\n",
    "    sns_prep.loc[:, [\"month\", \"duration\", \"playtime\", \"shuffle\", \"count\"]]\n",
    "    .groupby(by=\"month\")\n",
    "    .sum(numeric_only=True)\n",
    ")\n",
    "sns.barplot(data=sns_prep, x=sns_prep.index, y=\"count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common keys of listened tracks\n",
    "no_skip_df.loc[:, \"timestamp\"] = no_skip_df.loc[:, \"timestamp\"].astype(str)\n",
    "pivot_track = pd.DataFrame(\n",
    "    no_skip_df.drop_duplicates(subset=\"timestamp\")\n",
    "    .pivot_table(columns=[\"key_signature\"], aggfunc=\"size\")\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "pivot_track\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def show_transformations(df, song, transformation=\"all\"):\n",
    "#     song_key = df.query(\"(id == @song)\")[\"camelot\"]\n",
    "#     # print(song_key)\n",
    "#     keys = wheel_df.loc[transformation, song_key].reset_index(drop=True)\n",
    "#     # print(type(keys))\n",
    "#     print(keys[0])\n",
    "#     return df.query(\"camelot.isin(@keys[0])\", engine=\"python\")\n",
    "\n",
    "\n",
    "# fuck = show_transformations(streams_af_df, \"115RufHm0zvrPN3MaheZ98\", [\"major\"])\n",
    "# fuck\n",
    "# # song_key = playlist_af_df.loc[1, \"camelot\"]\n",
    "# # friendkey = wheel_df.loc[\"dominant_relative\", song_key]\n",
    "# # playlist_af_df.query(\"camelot in @friendkey\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This version works with uri\n",
    "# #should also have function to get uri from song title + artist\n",
    "# #todo: proper type hinting and default values\n",
    "# # separate functions i suppose, maybe with decorators\n",
    "# # https://stackoverflow.com/questions/62153371/best-way-to-create-python-function-with-multiple-options\n",
    "\n",
    "\n",
    "get_friendly(\n",
    "    streams_af_df, tempo_range=10, uri=\"5jh3f8fy8a335XYDyJ7x9R\", shift=[\"all\"]\n",
    ").sort_values(by=\"track\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How often do I play songs with \"birthday\" in the name on my loved ones' birthdays?\n",
    "streams_af_df.query(\"(playtime / duration) > 0.1\").query(\n",
    "    \"track.str.contains('(?i)birthday')\"\n",
    ").sort_values(by=[\"month\", \"date\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: plot podcast listening vs music listening\n",
    "# Totals per month\n",
    "podcasts_2020 = pod_df.copy()\n",
    "podcasts_2020[\"playtime\"] = podcasts_2020[\"playtime\"].copy() / 3600\n",
    "podcast_per_month = podcasts_2020.groupby(by=\"month\").sum(numeric_only=True)\n",
    "podcast_per_month[\"playtime\"]\n",
    "sns.barplot(\n",
    "    data=podcast_per_month, x=podcast_per_month[\"playtime\"], y=podcast_per_month.index\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: plot podcast listening vs music listening\n",
    "# damn i really spent most of january 2022 listening to podcats\n",
    "# podm_gb = podm.groupby(by=podm.index).sum(numeric_only=True)\n",
    "\n",
    "def plothpm(df_gb):\n",
    "    sns.barplot(data=df_gb.iloc[0:0], x=df_gb.values, y=df_gb.index)\n",
    "\n",
    "plothpm(hpm(no_skip_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plothpm(hpm(streams_af_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_data import unpickl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import_all()\n",
    "pod = pod_df.copy()\n",
    "\n",
    "def custom_mean(df):\n",
    "    return df.mean(skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import_all()\n",
    "#Todo: figure out which level of this \n",
    "pod = pod_df.copy()\n",
    "pod.loc[:, \"hours\"] = pod_df.loc[:, \"playtime\"].copy() / 3600\n",
    "pod.index = pod.timestamp\n",
    "podm = pod.copy().loc[:,'hours'].resample(\"M\").apply(lambda x: np.sum(x.values)).round()\n",
    "podm_gb = podm.groupby(podm.index.strftime(\"%b\")).resample(\"Y\").apply(lambda x: np.sum(x.values)).round().droplevel(level=1)\n",
    "podm_gb = podm_gb.groupby(podm_gb.index).mean()\n",
    "podm_gb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg per month\n",
    "\n",
    "import matplotlib as plt\n",
    "plt.rcParams['figure.figsize']=(8,8)\n",
    "sns.barplot(data=podm_gb, x=podm_gb[\"hours\"], y=podm_gb.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hpm(pod):\n",
    "    #pod = pod_df.copy()\n",
    "    pod.loc[:, \"hours\"] = pod.loc[:, \"playtime\"].copy() / 3600\n",
    "    pod.index = pod.timestamp\n",
    "    podm = pod.copy().loc[:,'hours'].resample(\"M\").apply(lambda x: np.sum(x.values)).round()\n",
    "    podm_gb = podm.groupby(podm.index.strftime(\"%b\")).resample(\"Y\").apply(lambda x: np.sum(x.values)).round().droplevel(level=1)\n",
    "    podm_gb = podm_gb.groupby(podm_gb.index).mean()\n",
    "    return podm_gb\n",
    "\n",
    "podm_gb = hpm(pod_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "podm_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_sp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "eb80a6b1853b89918e135d5cc2eae4ed721cf24d0e7f528dd6b030cd1f3201cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
