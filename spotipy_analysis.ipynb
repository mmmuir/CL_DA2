{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pandas as pd\n",
    "import json\n",
    "import seaborn as sns\n",
    "from random import randint\n",
    "from main_data import (\n",
    "    key_to_camelot,\n",
    "    get_history,\n",
    "    open_wheel,\n",
    "    add_features,\n",
    "    get_playlist,\n",
    "    get_friendly,\n",
    "    pickl,\n",
    "    unpickl,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid = \"ec23ca502beb44ffb22173b68cd37d9a\"\n",
    "secret = \"556c805ce20848ed94194c081f0c96a8\"\n",
    "sp = spotipy.Spotify(\n",
    "    client_credentials_manager=SpotifyClientCredentials(\n",
    "        client_id=cid, client_secret=secret\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %store -r streams_df streams_af_df no_skip_df playlist_af_df\n",
    "# streams_df, streams_af_df, no_skip_df, playlist_af_df = streams_df, streams_af_df, no_skip_df, playlist_af_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    all_streams_df,\n",
    "    streams_df,\n",
    "    streams_af_df,\n",
    "    no_skip_df,\n",
    "    playlist_af_df,\n",
    "    podcasts_df,\n",
    "    wheel_df,\n",
    ") = unpickl(\n",
    "    \"all_streams_df.p\",\n",
    "    \"streams_df.p\",\n",
    "    \"streams_af_df.p\",\n",
    "    \"no_skip_df.p\",\n",
    "    \"playlist_af_df.p\",\n",
    "    \"podcasts_df.p\",\n",
    "    \"wheel_df.p\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# series2 = streams_af_df['spotify_track_uri']\n",
    "# series1 = streams['spotify_track_uri']\n",
    "# comparison = series1[~series1.isin(series2)]\n",
    "# comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_skip_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sp.audio_features('77cVT85pU7WH3elC1SE7Uu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# streams.query('spotify_track_uri in @comparison')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_tracks = []\n",
    "# for i in range(len(comparison)):\n",
    "#     missing_tracks.append(sp.track(comparison.iloc[i])['external_urls'])\n",
    "# missing_tracks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streams_af_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streams_af_df[streams_af_df.ts.astype(str).duplicated() == True].sort_values(by=\"ts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't recall listening to this artist so much. Investigating if it was on repeat on accident or something.\n",
    "\n",
    "why_tala = streams_af_df.query('\"Hope Tala\" in artist')\n",
    "why_why_tala = (\n",
    "    why_tala.groupby(by=\"date\")\n",
    "    .sum(numeric_only=True)\n",
    "    .sort_values(by=\"ms_played\", ascending=False)\n",
    ")\n",
    "why_why_tala[\"ms_played\"] = why_why_tala[\"ms_played\"].apply(lambda x: x / 60000)\n",
    "why_why_tala.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like I just let her run on most popular song repeat for a few hours.\n",
    "streams_af_df.query('date == \"11/27/2019\"').sort_values(by=\"ts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_skip_df.query('artist.str.contains(\"(?i)miles davis\")', engine=\"python\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_songs(years=\"all\", skips=False, features=True):\n",
    "    if skips and features:\n",
    "        df = streams_af_df\n",
    "    elif not skips:\n",
    "        df = df.query(\"(ms_played / duration_ms) > 0.51\").reset_index()\n",
    "\n",
    "\n",
    "pivot_track = pd.DataFrame(\n",
    "    no_skip_df.query('year == \"2022\"')\n",
    "    .pivot_table(columns=[\"artist\", \"track\", \"year\"], aggfunc=\"size\")\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "pivot_track.head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_skip_df.query('year == \"2022\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check for tracks missing from new df\n",
    "# series1 = duration_prep['spotify_track_uri']\n",
    "# series2 = local_features['uri']\n",
    "# comparison = series1[~series1.isin(series2)]\n",
    "# comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show missing track URLs for further investigation; track is likely removed or yet to be analyzed for audio_features.\n",
    "# missing_tracks = []\n",
    "# for i in range(len(comparison)):\n",
    "#     missing_tracks.append(sp.track(comparison.iloc[i])['external_urls'])\n",
    "# missing_tracks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most played tracks\n",
    "pivot_track = pd.DataFrame(\n",
    "    no_skip_df.pivot_table(columns=[\"artist\", \"track\"], aggfunc=\"size\").sort_values(\n",
    "        ascending=False\n",
    "    )\n",
    ")\n",
    "pivot_track\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most listened to artists by number of songs played\n",
    "pivot_artist = pd.DataFrame(\n",
    "    no_skip_df.pivot_table(columns=[\"artist\"], aggfunc=\"size\").sort_values(\n",
    "        ascending=False\n",
    "    )\n",
    ")\n",
    "pivot_artist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_skip_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miles = no_skip_df.query('artist.str.contains(\"(?i)Miles Davis\")')\n",
    "pivot_miles = pd.pivot_table(miles, values=\"ms_played\", index=[\"album\"], aggfunc=\"sum\")\n",
    "pivot_miles = pivot_miles.sort_values(by=\"ms_played\", ascending=False)\n",
    "miles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_album_time = pd.pivot_table(\n",
    "    no_skip_df, values=\"ms_played\", index=[\"album\"], aggfunc=\"sum\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_album_time = pivot_album_time.sort_values(by=\"ms_played\", ascending=False)\n",
    "pivot_album_time.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_artist_time = pd.pivot_table(\n",
    "    no_skip_df, values=\"ms_played\", index=[\"artist\"], aggfunc=\"sum\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pivot_artist_time.sort_values().to_string())\n",
    "artist_time = pivot_artist_time.sort_values(\n",
    "    by=\"ms_played\", ascending=False\n",
    ").reset_index()\n",
    "print(artist_time.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artists played more than 10 mins\n",
    "repeated_artists = artist_time[:1750]\n",
    "# Number of unique tracks played from those artists\n",
    "\n",
    "len(streams_af_df[\"track\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "still_repeated = repeated_artists[\"artist\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of unique tracks per artist and create ascending list\n",
    "still_still_repeated = no_skip_df.query(\"artist in @still_repeated\")\n",
    "# still_still_repeated.loc[:, 'artist'] = still_still_repeated.copy().loc[:, 'artist'].astype(str)\n",
    "group = still_still_repeated.groupby(\"artist\")\n",
    "songs_per_artist = group.apply(lambda x: x[\"track\"].unique())\n",
    "unique_songs = songs_per_artist.reset_index(name=\"unique_titles\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_songs[\"unique_count\"] = unique_songs.iloc[:, 1].str.len()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_songs = unique_songs.sort_values(by=\"unique_count\").reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_export = unique_songs.query(\"unique_count <= 8\")[\"artist\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_artist_time.ms_played\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artists with 10 or less songs played that I've heard more than an hour of. Indicative of artists I should explore more of.\n",
    "pivot_artist_time.query(\"ms_played > 3600000\").query(\"artist in @unique_export\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo: Next step after the above is to plot least uniques with most ms played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert\n",
    "pivot_artist_time[\"ms_played\"] = pd.to_timedelta(pivot_artist_time.ms_played, unit=\"ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_td(td):\n",
    "    \"\"\"Converts timedelta to hh:mm:ss strictly for presentation purposes\"\"\"\n",
    "    minutes, seconds = divmod(td.seconds + td.days * 86400, 60)\n",
    "    hours, minutes = divmod(minutes, 60)\n",
    "    return \"{:d}:{:02d}:{:02d}\".format(hours, minutes, seconds, td.microseconds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_artist_time[\"ms_played\"] = pivot_artist_time[\"ms_played\"].apply(format_td)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show longest songs\n",
    "no_skip_df.sort_values(by=\"ms_played\", axis=0, ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to control this for missing months? do october 25 2019 thru 2022\n",
    "sns_prep = streams_af_df.query('year == \"2019\"| year == \"2020\" | year == \"2021\"')\n",
    "sns_prep = pd.pivot_table(\n",
    "    sns_prep,\n",
    "    values=\"ms_played\",\n",
    "    index=[\"month\"],\n",
    "    aggfunc=\"sum\",\n",
    ").reset_index()\n",
    "sns_prep[\"hours played\"] = sns_prep[\"ms_played\"].apply(lambda x: x / 3600000)\n",
    "sns.barplot(data=sns_prep, x=\"month\", y=\"hours played\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of unique uris closely maps to total skips per month\n",
    "sns_prep = streams_af_df.copy().drop_duplicates(subset=\"id\")\n",
    "sns_prep[\"count\"] = 1\n",
    "sns_prep = (\n",
    "    sns_prep.loc[:, [\"month\", \"duration_ms\", \"ms_played\", \"shuffle\", \"count\"]]\n",
    "    .groupby(by=\"month\")\n",
    "    .sum(numeric_only=True)\n",
    ")\n",
    "sns.barplot(data=sns_prep, x=sns_prep.index, y=\"count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good way to find months with most music discovery along with unique URIs\n",
    "sns_prep = streams_af_df.copy().query(\"(ms_played / duration_ms) < 0.25\")\n",
    "sns_prep.at[:, \"count\"] = 1\n",
    "sns_prep = (\n",
    "    sns_prep.loc[:, [\"month\", \"duration_ms\", \"ms_played\", \"shuffle\", \"count\"]]\n",
    "    .groupby(by=\"month\")\n",
    "    .sum(numeric_only=True)\n",
    ")\n",
    "sns.barplot(data=sns_prep, x=sns_prep.index, y=\"count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common keys of listened tracks\n",
    "no_skip_df.loc[:, \"ts\"] = no_skip_df.loc[:, \"ts\"].astype(str)\n",
    "pivot_track = pd.DataFrame(\n",
    "    no_skip_df.drop_duplicates(subset=\"ts\")\n",
    "    .pivot_table(columns=[\"key_signature\"], aggfunc=\"size\")\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "pivot_track\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def show_transformations(df, song, transformation=\"all\"):\n",
    "#     song_key = df.query(\"(id == @song)\")[\"camelot\"]\n",
    "#     # print(song_key)\n",
    "#     keys = wheel_df.loc[transformation, song_key].reset_index(drop=True)\n",
    "#     # print(type(keys))\n",
    "#     print(keys[0])\n",
    "#     return df.query(\"camelot.isin(@keys[0])\", engine=\"python\")\n",
    "\n",
    "\n",
    "# fuck = show_transformations(streams_af_df, \"115RufHm0zvrPN3MaheZ98\", [\"major\"])\n",
    "# fuck\n",
    "# # song_key = playlist_af_df.loc[1, \"camelot\"]\n",
    "# # friendkey = wheel_df.loc[\"dominant_relative\", song_key]\n",
    "# # playlist_af_df.query(\"camelot in @friendkey\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This version works with uri\n",
    "# #should also have function to get uri from song title + artist\n",
    "# #todo: proper type hinting and default values\n",
    "# # separate functions i suppose, maybe with decorators\n",
    "# # https://stackoverflow.com/questions/62153371/best-way-to-create-python-function-with-multiple-options\n",
    "\n",
    "\n",
    "get_friendly(\n",
    "    streams_af_df, tempo_range=10, uri=\"5jh3f8fy8a335XYDyJ7x9R\", shift=[\"all\"]\n",
    ").sort_values(by=\"track\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How often do I play songs with \"birthday\" in the name on my loved ones' birthdays?\n",
    "streams_af_df.query('(ms_played / duration_ms) > 0.1').query(\"track.str.contains('(?i)birthday')\").sort_values(by=['month', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [75], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m podcast_per_month \u001b[39m=\u001b[39m podcasts_df\u001b[39m.\u001b[39mgroupby(by\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmonth\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39msum(numeric_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m sns\u001b[39m.\u001b[39;49mbarplot(data\u001b[39m=\u001b[39;49mpodcast_per_month, x\u001b[39m=\u001b[39;49mpodcast_per_month, y\u001b[39m=\u001b[39;49mpodcast_per_month\u001b[39m.\u001b[39;49mindex)\n",
      "File \u001b[0;32m~/git/CL_DA2/venv_sp/lib/python3.9/site-packages/seaborn/categorical.py:2754\u001b[0m, in \u001b[0;36mbarplot\u001b[0;34m(data, x, y, hue, order, hue_order, estimator, errorbar, n_boot, units, seed, orient, color, palette, saturation, width, errcolor, errwidth, capsize, dodge, ci, ax, **kwargs)\u001b[0m\n\u001b[1;32m   2751\u001b[0m \u001b[39mif\u001b[39;00m estimator \u001b[39mis\u001b[39;00m \u001b[39mlen\u001b[39m:\n\u001b[1;32m   2752\u001b[0m     estimator \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msize\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 2754\u001b[0m plotter \u001b[39m=\u001b[39m _BarPlotter(x, y, hue, data, order, hue_order,\n\u001b[1;32m   2755\u001b[0m                       estimator, errorbar, n_boot, units, seed,\n\u001b[1;32m   2756\u001b[0m                       orient, color, palette, saturation,\n\u001b[1;32m   2757\u001b[0m                       width, errcolor, errwidth, capsize, dodge)\n\u001b[1;32m   2759\u001b[0m \u001b[39mif\u001b[39;00m ax \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2760\u001b[0m     ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mgca()\n",
      "File \u001b[0;32m~/git/CL_DA2/venv_sp/lib/python3.9/site-packages/seaborn/categorical.py:1530\u001b[0m, in \u001b[0;36m_BarPlotter.__init__\u001b[0;34m(self, x, y, hue, data, order, hue_order, estimator, errorbar, n_boot, units, seed, orient, color, palette, saturation, width, errcolor, errwidth, capsize, dodge)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, x, y, hue, data, order, hue_order,\n\u001b[1;32m   1526\u001b[0m              estimator, errorbar, n_boot, units, seed,\n\u001b[1;32m   1527\u001b[0m              orient, color, palette, saturation, width,\n\u001b[1;32m   1528\u001b[0m              errcolor, errwidth, capsize, dodge):\n\u001b[1;32m   1529\u001b[0m     \u001b[39m\"\"\"Initialize the plotter.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1530\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestablish_variables(x, y, hue, data, orient,\n\u001b[1;32m   1531\u001b[0m                              order, hue_order, units)\n\u001b[1;32m   1532\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestablish_colors(color, palette, saturation)\n\u001b[1;32m   1533\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimate_statistic(estimator, errorbar, n_boot, seed)\n",
      "File \u001b[0;32m~/git/CL_DA2/venv_sp/lib/python3.9/site-packages/seaborn/categorical.py:544\u001b[0m, in \u001b[0;36m_CategoricalPlotter.establish_variables\u001b[0;34m(self, x, y, hue, data, orient, order, hue_order, units)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err)\n\u001b[1;32m    543\u001b[0m \u001b[39m# Figure out the plotting orientation\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m orient \u001b[39m=\u001b[39m infer_orient(\n\u001b[1;32m    545\u001b[0m     x, y, orient, require_numeric\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequire_numeric\n\u001b[1;32m    546\u001b[0m )\n\u001b[1;32m    548\u001b[0m \u001b[39m# Option 2a:\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[39m# We are plotting a single set of data\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \u001b[39m# ------------------------------------\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    552\u001b[0m \n\u001b[1;32m    553\u001b[0m     \u001b[39m# Determine where the data are\u001b[39;00m\n",
      "File \u001b[0;32m~/git/CL_DA2/venv_sp/lib/python3.9/site-packages/seaborn/_oldcore.py:1584\u001b[0m, in \u001b[0;36minfer_orient\u001b[0;34m(x, y, orient, require_numeric)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minfer_orient\u001b[39m(x\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, orient\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, require_numeric\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\"\"Determine how the plot should be oriented based on the data.\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \n\u001b[1;32m   1559\u001b[0m \u001b[39m    For historical reasons, the convention is to call a plot \"horizontally\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1581\u001b[0m \n\u001b[1;32m   1582\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1584\u001b[0m     x_type \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m variable_type(x)\n\u001b[1;32m   1585\u001b[0m     y_type \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m variable_type(y)\n\u001b[1;32m   1587\u001b[0m     nonnumeric_dv_error \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m orientation requires numeric `\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m` variable.\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/git/CL_DA2/venv_sp/lib/python3.9/site-packages/seaborn/_oldcore.py:1502\u001b[0m, in \u001b[0;36mvariable_type\u001b[0;34m(vector, boolean_type)\u001b[0m\n\u001b[1;32m   1499\u001b[0m     \u001b[39mreturn\u001b[39;00m VariableType(\u001b[39m\"\u001b[39m\u001b[39mcategorical\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1501\u001b[0m \u001b[39m# Special-case all-na data, which is always \"numeric\"\u001b[39;00m\n\u001b[0;32m-> 1502\u001b[0m \u001b[39mif\u001b[39;00m pd\u001b[39m.\u001b[39misna(vector)\u001b[39m.\u001b[39mall():\n\u001b[1;32m   1503\u001b[0m     \u001b[39mreturn\u001b[39;00m VariableType(\u001b[39m\"\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1505\u001b[0m \u001b[39m# Special-case binary/boolean data, allow caller to determine\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m \u001b[39m# This triggers a numpy warning when vector has strings/objects\u001b[39;00m\n\u001b[1;32m   1507\u001b[0m \u001b[39m# https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1511\u001b[0m \u001b[39m# https://github.com/numpy/numpy/issues/13548\u001b[39;00m\n\u001b[1;32m   1512\u001b[0m \u001b[39m# This is considered a bug by numpy and will likely go away.\u001b[39;00m\n",
      "File \u001b[0;32m~/git/CL_DA2/venv_sp/lib/python3.9/site-packages/pandas/core/generic.py:1527\u001b[0m, in \u001b[0;36mNDFrame.__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m   1526\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__nonzero__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NoReturn:\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1528\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe truth value of a \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m is ambiguous. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1529\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUse a.empty, a.bool(), a.item(), a.any() or a.all().\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1530\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "podcast_per_month = podcasts_df.groupby(by=\"month\").sum(numeric_only=True)\n",
    "sns.barplot(data=podcast_per_month, x=podcast_per_month, y=podcast_per_month.index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 ('venv_sp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "6c8bf7f0555c32900acd711d853e09cdea56c6cb38ebfb9f86148bd2d72dff69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
