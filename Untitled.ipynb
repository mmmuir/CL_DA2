{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# jupyter:\n",
    "#   jupytext:\n",
    "#     cell_metadata_filter: -all\n",
    "#     custom_cell_magics: kql\n",
    "#     text_representation:\n",
    "#       extension: .py\n",
    "#       format_name: percent\n",
    "#       format_version: '1.3'\n",
    "#       jupytext_version: 1.11.2\n",
    "#   kernelspec:\n",
    "#     display_name: venv_sp\n",
    "#     language: python\n",
    "#     name: python3\n",
    "# ---\n",
    "\n",
    "# %%\n",
    "import json\n",
    "from os import path\n",
    "from glob import glob\n",
    "from random import randint\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pandas as pd\n",
    "from numpy import nan, where\n",
    "from ratelimit import limits\n",
    "\n",
    "\n",
    "# %%\n",
    "# Instantiate Spotipy\n",
    "cid = \"ec23ca502beb44ffb22173b68cd37d9a\"\n",
    "secret = \"556c805ce20848ed94194c081f0c96a8\"\n",
    "sp = spotipy.Spotify(\n",
    "    client_credentials_manager=SpotifyClientCredentials(\n",
    "        client_id=cid, client_secret=secret\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# %%\n",
    "def get_history():\n",
    "    \"\"\"_summary_\n",
    "        Convert extended streaming history to DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        _description_\n",
    "\n",
    "    \"\"\"\n",
    "    json_concat = []\n",
    "    history = glob(path.join(\"data\", \"endsong*.json\"))\n",
    "    for i in range(len(history)):\n",
    "\n",
    "        if len(history) == 1:\n",
    "\n",
    "            with open(path.join(\"data\", \"endsong.json\"), encoding=\"utf-8\") as json_file:\n",
    "                user_json = json.load(json_file)\n",
    "                json_concat.append(user_json)\n",
    "        elif history:\n",
    "            with open(\n",
    "                path.join(\"data\", f\"endsong_{i}.json\"), encoding=\"utf-8\"\n",
    "            ) as json_file:\n",
    "                user_json = json.load(json_file)\n",
    "                json_concat.append(user_json)\n",
    "        elif not history:\n",
    "            print(\n",
    "                \"No streaming history in the current working directory. Visit https://www.spotify.com/account/privacy/ to request your extended streaming history and move the endsong.json files to the notebook directory to run analyses on your extended history.\"\n",
    "            )\n",
    "            break\n",
    "    df = (\n",
    "        pd.DataFrame([j for i in json_concat for j in i])\n",
    "        .drop(\n",
    "            columns=[\n",
    "                \"username\",\n",
    "                \"conn_country\",\n",
    "                \"ip_addr_decrypted\",\n",
    "                \"user_agent_decrypted\",\n",
    "                \"platform\",\n",
    "                \"incognito_mode\",\n",
    "                \"offline_timestamp\",\n",
    "                \"offline\",\n",
    "                \"skipped\",\n",
    "            ]\n",
    "        )\n",
    "        .rename(\n",
    "            columns={\n",
    "                \"master_metadata_track_name\": \"track\",\n",
    "                \"master_metadata_album_artist_name\": \"artist\",\n",
    "                \"master_metadata_album_album_name\": \"album\",\n",
    "                \"reason_start\": \"start\",\n",
    "                \"reason_end\": \"end\",\n",
    "                \"episode_name\": \"episode\",\n",
    "                \"episode_show_name\": \"show\",\n",
    "                \"spotify_track_uri\": \"id\",\n",
    "            }\n",
    "        )\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    # Provide interoperability with API data, which uses \"id\" instead of \"spotify_track_uri\"\n",
    "    df[\"ts\"] = pd.to_datetime(df[\"ts\"])\n",
    "    df[\"ddate\"] = df[\"ts\"].apply(lambda x: x.date)\n",
    "    df[\"dtime\"] = df[\"ts\"].apply(lambda x: x.time)\n",
    "    df[\"date\"] = df.ts.dt.strftime(\"%m/%d/%Y\")\n",
    "    df[\"time\"] = df.ts.dt.strftime(\"%H:%M:%S\")\n",
    "    df[\"month\"] = df.ts.dt.strftime(\"%b\")\n",
    "    df[\"year\"] = df.ts.dt.strftime(\"%Y\")\n",
    "    df[\"day\"] = df.ts.dt.strftime(\"%a\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# %%\n",
    "def get_podcasts(df):\n",
    "    return (\n",
    "        df[df[\"id\"].isnull()]\n",
    "        .reset_index(drop=True)\n",
    "        .drop(columns=[\"track\", \"artist\", \"album\", \"id\", \"shuffle\"])\n",
    "    )\n",
    "\n",
    "\n",
    "# %%\n",
    "def remove_podcasts(df):\n",
    "    # Drop podcast episodes. Reorder columns.\n",
    "    df = (\n",
    "        df.fillna(value=nan)  # Todo: keep nan or no\n",
    "        .loc[df[\"episode\"].isna()]\n",
    "        .drop(\n",
    "            columns=[\n",
    "                \"spotify_episode_uri\",\n",
    "                \"episode\",\n",
    "                \"show\",\n",
    "            ]\n",
    "        )\n",
    "    ).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# %%\n",
    "def get_playlist(uri):\n",
    "    playlist_df = []\n",
    "    offset = 0\n",
    "    while True:\n",
    "        res = sp.playlist_tracks(\n",
    "            uri,\n",
    "            offset=offset,\n",
    "            fields=\"items.track.id,items.track.artists,items.track.name,items.track.album,total\",\n",
    "        )\n",
    "        if len(res[\"items\"]) == 0:\n",
    "            # Combine inner lists and exit loop\n",
    "            # Todo: ask how this comprehension actually works\n",
    "            playlist_df = [j for i in playlist_df for j in i]\n",
    "            break\n",
    "        playlist_df.append(res[\"items\"])\n",
    "        offset = offset + len(res[\"items\"])\n",
    "        print(offset, \"/\", res[\"total\"])\n",
    "    artist_dict = {\"artist\": [], \"track\": [], \"id\": [], \"album\": []}\n",
    "    for i in range(len(playlist_df)):\n",
    "        artist_dict[\"artist\"].append(playlist_df[i][\"track\"][\"artists\"][0][\"name\"])\n",
    "        artist_dict[\"track\"].append(playlist_df[i][\"track\"][\"name\"])\n",
    "        artist_dict[\"id\"].append(playlist_df[i][\"track\"][\"id\"])\n",
    "        artist_dict[\"album\"].append(playlist_df[i][\"track\"][\"album\"][\"name\"])\n",
    "    df = pd.DataFrame(artist_dict)\n",
    "    return df\n",
    "\n",
    "\n",
    "# %%\n",
    "def open_wheel():\n",
    "    with open(path.join(\"data\", \"camelot.json\")) as json_file:\n",
    "        camelot_json = json.load(json_file)\n",
    "        camelot_wheel = pd.DataFrame.from_dict(camelot_json)\n",
    "        return camelot_wheel\n",
    "\n",
    "\n",
    "# %%\n",
    "def key_to_camelot(df):\n",
    "    df[\"key\"] = (\n",
    "        df[\"key\"]\n",
    "        .astype(str)\n",
    "        .replace(\n",
    "            {\n",
    "                \"-1\": \"no key detected\",\n",
    "                \"0\": \"C\",\n",
    "                \"1\": \"D-flat\",\n",
    "                \"2\": \"D\",\n",
    "                \"3\": \"E-flat\",\n",
    "                \"4\": \"E\",\n",
    "                \"5\": \"F\",\n",
    "                \"6\": \"F-sharp\",\n",
    "                \"7\": \"G\",\n",
    "                \"8\": \"A-flat\",\n",
    "                \"9\": \"A\",\n",
    "                \"10\": \"B-flat\",\n",
    "                \"11\": \"B\",\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df[\"mode\"] = where(df[\"mode\"] == 1, \"major\", \"minor\")\n",
    "    df[\"key_signature\"] = df[\"key\"] + \" \" + df[\"mode\"]\n",
    "\n",
    "    wheel_df = open_wheel().iloc[0]\n",
    "\n",
    "    # Convert diatonic key signatures to Camelot wheel equivalents.\n",
    "    df[\"camelot\"] = df[\"key_signature\"].map(\n",
    "        lambda x: wheel_df.loc[wheel_df == x].index[0]\n",
    "    )\n",
    "    df = df.drop(columns=[\"key\", \"mode\"])\n",
    "\n",
    "\n",
    "# %%\n",
    "@limits(calls=200, period=30)\n",
    "def add_features(df, length=None, playlist=None):\n",
    "    # Specify length for testing purposes\n",
    "    df = df[:length]\n",
    "    # Drop duplicates to limit API calls to include only unique URIs\n",
    "    df_query = df.drop_duplicates(subset=\"id\")\n",
    "    offset_min = 0\n",
    "    offset_max = 50\n",
    "    af_res_list = []\n",
    "    while True:\n",
    "        if offset_min > len(df_query):\n",
    "            af_res_list = [j for i in af_res_list for j in i]\n",
    "            merge_cols = pd.DataFrame(af_res_list).loc[\n",
    "                :, [\"tempo\", \"duration_ms\", \"id\", \"key\", \"mode\"]\n",
    "            ]\n",
    "            key_to_camelot(merge_cols)\n",
    "            merge_cols = pd.merge(merge_cols, df)\n",
    "            # Todo: separate function so we can remove these col names from streams_df too in get_history()\n",
    "            merge_cols = merge_cols.rename(\n",
    "                columns={\n",
    "                    \"master_metadata_track_name\": \"track\",\n",
    "                    \"master_metadata_album_artist_name\": \"artist\",\n",
    "                    \"master_metadata_album_album_name\": \"album\",\n",
    "                    \"reason_start\": \"start\",\n",
    "                    \"reason_end\": \"end\",\n",
    "                }\n",
    "            )\n",
    "            if playlist:\n",
    "                merge_cols = merge_cols[\n",
    "                    [\n",
    "                        \"artist\",\n",
    "                        \"track\",\n",
    "                        \"album\",\n",
    "                        \"tempo\",\n",
    "                        \"camelot\",\n",
    "                        \"key_signature\",\n",
    "                        \"id\",\n",
    "                    ]\n",
    "                ]\n",
    "            elif not playlist:\n",
    "                merge_cols = merge_cols[\n",
    "                    [\n",
    "                        \"artist\",\n",
    "                        \"track\",\n",
    "                        \"album\",\n",
    "                        \"duration_ms\",\n",
    "                        \"ms_played\",\n",
    "                        \"date\",\n",
    "                        \"time\",\n",
    "                        \"month\",\n",
    "                        \"year\",\n",
    "                        \"tempo\",\n",
    "                        \"camelot\",\n",
    "                        \"key_signature\",\n",
    "                        \"start\",\n",
    "                        \"end\",\n",
    "                        \"shuffle\",\n",
    "                        \"id\",\n",
    "                        \"ts\",\n",
    "                    ]\n",
    "                ]\n",
    "                merge_cols[\"date\"] = merge_cols[\"date\"].astype(str)\n",
    "            # Round tempos to nearest whole number for easier. Playlist generation works with tempo ranges, so decimal precision is unnecessary.\n",
    "            merge_cols[\"tempo\"] = round(merge_cols[\"tempo\"]).astype(\n",
    "                int\n",
    "            )  # Todo: delete this if it breaks main\n",
    "            return merge_cols\n",
    "        res = sp.audio_features(\n",
    "            df_query[\"id\"].iloc[offset_min:offset_max],\n",
    "        )\n",
    "        if None not in res:\n",
    "            af_res_list.append(res)\n",
    "        else:\n",
    "            res.remove(None)\n",
    "            af_res_list.append(res)\n",
    "        offset_min += 50\n",
    "        offset_max += 50\n",
    "\n",
    "\n",
    "# %%\n",
    "# # This version works with uri\n",
    "# #should also have function to get uri from song title + artist\n",
    "# #todo: proper type hinting and default values\n",
    "# # separate functions i suppose, maybe with decorators\n",
    "# # https://stackoverflow.com/questions/62153371/best-way-to-create-python-function-with-multiple-options\n",
    "\n",
    "\n",
    "def get_friendly(\n",
    "    df,\n",
    "    tempo_range=10,\n",
    "    uri=None,\n",
    "    index=None,\n",
    "    shuffle=None,\n",
    "    playlist=False,\n",
    "    shift=[\"all\"],\n",
    "):\n",
    "    wheel = open_wheel()\n",
    "    df = df.drop_duplicates(subset=\"id\").reset_index()\n",
    "    if uri:\n",
    "        song_selected = df.loc[df[\"id\"] == uri].iloc[0]\n",
    "    elif index or index == 0:\n",
    "        song_selected = df.loc[index]\n",
    "    elif shuffle:\n",
    "        song_selected = df.iloc[randint(0, len(df) - 1)]\n",
    "    else:\n",
    "        print(\n",
    "            \"Error: no song selected. Specify shuffle=True to operate on random song.\"\n",
    "        )\n",
    "    # Designate desired tempo range\n",
    "    selected_tempo = song_selected[\"tempo\"]\n",
    "    acceptable_tempos = range(\n",
    "        (selected_tempo - tempo_range), (selected_tempo + tempo_range), 1\n",
    "    )\n",
    "\n",
    "    # Select harmonically compatible key signatures in camelot.json\n",
    "    friendly_keys = []\n",
    "    for i in range(len(shift)):\n",
    "        key = wheel[song_selected[\"camelot\"]][shift[i]]\n",
    "        friendly_keys.append(key)\n",
    "        print(key)\n",
    "        if type(key) == list:\n",
    "            friendly_keys.extend(key)\n",
    "\n",
    "    # Show tracks with harmonically compatible key signatures within a given tempo range. Accounts for Spotify's tendency to double or halve numeric tempos.\n",
    "\n",
    "    return df.query(\n",
    "        \"camelot in @friendly_keys & (tempo in @acceptable_tempos | tempo * 2 in @acceptable_tempos | tempo / 2 in @acceptable_tempos)\"\n",
    "    )\n",
    "\n",
    "\n",
    "# %%\n",
    "def pickl(df, name):\n",
    "    return df.to_pickle(path.join(\"data\", name))\n",
    "\n",
    "\n",
    "# %%\n",
    "def unpickl(*df):\n",
    "    for name in df:\n",
    "        yield pd.read_pickle(path.join(\"data\", name))\n",
    "\n",
    "\n",
    "# %%\n",
    "def main():\n",
    "    # Example playlist\n",
    "    uri = \"spotify:playlist:5CF6KvWn85N6DoWufOjP5T\"\n",
    "    # Todo: delete for production\n",
    "    testlength = None\n",
    "\n",
    "    all_streams_df = get_history()\n",
    "    podcasts_df = get_podcasts(all_streams_df)\n",
    "    streams_df = remove_podcasts(all_streams_df)\n",
    "    #streams_af_df = add_features(streams_df, length=testlength)\n",
    "    #playlist_af_df = add_features(get_playlist(uri), length=testlength, playlist=True)\n",
    "    #no_skip_df = streams_af_df.query(\"(ms_played / duration_ms) > 0.75\").reset_index(\n",
    "       # drop=True\n",
    "    #)\n",
    "    #wheel_df = open_wheel()\n",
    "    #return streams_df, streams_af_df, no_skip_df, playlist_af_df, podcasts_df, all_streams_df, wheel_df\n",
    "    pickl(streams_df, name=\"streams_df.p\")\n",
    "    # pickl(streams_af_df, name=\"streams_af_df.p\")\n",
    "    # pickl(no_skip_df, name=\"no_skip_df.p\")\n",
    "    # pickl(playlist_af_df, name=\"playlist_af_df.p\")\n",
    "    pickl(podcasts_df, name=\"podcasts_df.p\")\n",
    "    pickl(all_streams_df, name=\"all_streams_df.p\")\n",
    "    # pickl(wheel_df, name=\"wheel_df.p\")\n",
    "\n",
    "\n",
    "# %%\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "main()\n",
    "# %%\n",
    "# Run this to get runtime statistics and store variables separately from pickle files. %stored variables can be found in\n",
    "#%prun -r streams_df, streams_af_df, no_skip_df, playlist_af_df, podcasts_df, all_streams_df, wheel_df = main()\n",
    "#%store streams_df streams_af_df no_skip_df playlist_af_df podcasts_df all_streams_df wheel_df\n",
    "# # %prun -r streams_df, streams_af_df, no_skip_df, playlist_af_df, all_streams_df, wheel_df = main()\n",
    "# # %store streams_df streams_af_df no_skip_df playlist_af_df all_streams_df wheel_df\n",
    "\n",
    "# %%\n",
    "# # %store streams_df streams_af_df no_skip_df playlist_af_df podcasts_df all_streams_df wheel_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'streams_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstreams_df\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'streams_df' is not defined"
     ]
    }
   ],
   "source": [
    "streams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
